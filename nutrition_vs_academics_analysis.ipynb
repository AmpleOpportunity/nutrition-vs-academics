{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nutrition-vs-academics-analysis",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPL2yv76JtM6Hf6I98hzw2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmpleOpportunity/nutrition-vs-academics/blob/master/nutrition_vs_academics_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN8ogF3oBc7j",
        "colab_type": "text"
      },
      "source": [
        "# Correlations Between Nutritional Identification and Grade Point Average Among College Students\n",
        "\n",
        "## Problem Statement\n",
        "Lifestyle choices have a correlation on health; the innumerable studies on smoking risks, obesity effects, and other comorbidities have plenty to offer on these subjects. With childhood obesity a growing concern, there is a rising interest in healthy school lunches and nutritional reformation for young adults. \n",
        "\n",
        "While there are innumerable studies in the area of nutrition as well, many of the examinations focus on outcomes; primarily, a subject’s actual diet, either baselined from a point in time or versus another performance variable. This examination would focus on food identification, not consumption, among young adults. Specifically, the study would be taken to investigate whether students with higher academic performance also possess higher nutritional awareness. \n",
        "\n",
        "## Hypothesis\n",
        "Students who are more likely to identify with healthier meal options and more accurately predict the caloric density of foods, on average, have higher academic performance as measured by GPA.\n",
        "\n",
        "## Interest in Study\n",
        "As a person that suffered from childhood obesity and had to develop a healthy relationship with food as an adult, nutrition is something that is foundational to my life. Though many years of trying and failing to adopt a healthy lifestyle, success did not yield itself until I realized that health is a mindset rather than a set of actions; that it is not *what* I eat, but *how* I eat from a perceptual and emotional standpoint. This research focuses on that selfsame perception of food items.\n",
        "\n",
        "## Methodology \n",
        "Using the 2017 survey conducted by BoraPajo on [Kaggle](https://www.kaggle.com/borapajo/food-choices), perform the following analyses:\n",
        "1. Using GPA as the categorical variable, look for a correlation between respondents’ identification with healthier/unhealthier food options (oatmeal vs. donuts for breakfast, frappuccino vs espresso for coffee, orange juice vs soda for beverage, McDonalds french fries vs home fries for potatoes, and vegetable vs starchy for soup) and academic performance. Assuming data is normally-distributed, a Chi-squared Test would be appropriate to examine any statistically significant variability among these groups groups.\n",
        "\n",
        "1. Using GPA as the categorical variable, look for a correlation between correct calorie identification of given foods (chicken piadina, scone, burrito, and waffle potato sandwich) and academic performance. Assuming normal distribution, another Chi-squared Test would be appropriate again.\n",
        "\n",
        "1. Using an independent t-test, examine the correlation between the following:\n",
        "  - GPA and respondents’ self-perception of their diet (healthy, unhealthy, repetitive, unclear),\n",
        "  - GPA and respondents’ body weight self-identification (slim, very fit, just right, slightly overweight, overweight, does not consider weight self-identification)\n",
        "  - GPA and respondents’ likelihood to check nutritional values frequently (never, on certain products only, very rarely, on most products, on everything)\n",
        "\n",
        "1. Using a Chi-squared Test, analyze GPA versus the previous self-perception questions as a group.\n",
        "\n",
        "## Intended Audience\n",
        "Educational institutions can use the results of a positive experiment to provide greater emphasis on nutritional mindfulness as a part of increasing academic performance. The current focus on healthier school lunches, while positive, is more compulsory whereas a confirmation of the hypothesis could be used to place emphasis on willful selection of higher quality food items.\n",
        "\n",
        "Providers of educational instruction and coaching have the potential to use the results of the experiment to prioritize nutritional education as part of coaching study habits. Rather than focusing on study habits such as rote vs. mnemonic memorization, a more holistic approach may be adopted that students can apply more broadly.\n",
        "\n",
        "Producers for more health-conscious food products can place their offerings in front of the market segment of students and providers for students from the position that their product supports better educational outcomes when combined with a more mindful approach to diet and nutrition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVrC1emKklc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Students who are more likely to identify with healthier meal options and more \n",
        "accurately predict the caloric density of foods, on average, have higher \n",
        "academic performance as measured by GPA.'''\n",
        "\n",
        "# dependencies\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statsmodels.sandbox.stats.runs as sm\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# read csv to dataframe\n",
        "host = 'https://raw.githubusercontent.com/AmpleOpportunity/nutrition-vs-academics/master/food_coded.csv'\n",
        "food_choices_master_df = pd.read_csv(host)\n",
        "food_choices_master_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vxTu4rXr6EU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''For the purposes of this study, the only fields that will be used are those\n",
        "that contain food self-identification choices (calories_chicken, coffee, drink, \n",
        "fries, soup) as well as caloric identification of various food items \n",
        "(calories_chicken, calories_scone, tortilla_calories, waffle_calories) with GPA \n",
        "as the continuous variable throughout.'''\n",
        "\n",
        "# extract relevant data points for cleaning\n",
        "food_choices_extracted_df = food_choices_master_df[['GPA', 'breakfast', 'coffee', \n",
        "                                                   'drink', 'fries', 'soup', 'calories_chicken', \n",
        "                                                   'calories_scone', \n",
        "                                                   'tortilla_calories', \n",
        "                                                   'waffle_calories']]\n",
        "\n",
        "food_choices_extracted_df.info()\n",
        "\n",
        "'''The schema reveals some needed work before analysis. A few of the records are \n",
        "incomplete. Additionally, all data types should be interpreted as an integer or \n",
        "floating point number but GPA is interpreted as a string. All non-numerical \n",
        "records will be converted into null values for that column and then purged from \n",
        "the dataframe.'''\n",
        "\n",
        "# drop records where missing/non-numerical values exist\n",
        "food_choices_extracted_df['GPA'] = pd.to_numeric(food_choices_extracted_df['GPA'], \n",
        "                                               errors='coerce')\n",
        "\n",
        "food_choices_cleaned_df = food_choices_extracted_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkhuDUxHGow2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verify new sample size integrity\n",
        "print('{} records removed. Total records: {}.'.format(\n",
        "    len(food_choices_extracted_df) - len(food_choices_cleaned_df), \n",
        "    len(food_choices_cleaned_df)))\n",
        "\n",
        "'''The sample size is still robust enough to continue analysis.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FUC6evFbAoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comparing each group for normality by extracting kurtosis and skewness\n",
        "\n",
        "# create separate df to hold values\n",
        "normality_analysis_df = pd.DataFrame(columns=['name', 'kurtosis', 'skewness'])\n",
        "\n",
        "# iterate over food_choices_cleaned_df, compute kurtosis/skew, and append\n",
        "# results to normality_analysis_df\n",
        "for i in range(len(food_choices_cleaned_df.columns)):\n",
        "  normality_analysis_df = normality_analysis_df.append(pd.Series([food_choices_cleaned_df.columns[i],\n",
        "                                          stats.kurtosis(food_choices_cleaned_df.iloc[:, i]),\n",
        "                                          stats.skew(food_choices_cleaned_df.iloc[:, i])],\n",
        "                                         index=normality_analysis_df.columns),\n",
        "                               ignore_index=True)\n",
        "\n",
        "normality_analysis_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR7F2RaR-i5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''All skews are within acceptable ranges. breakfast and fries are leptokurtic.\n",
        "Further investigation is warranted.'''\n",
        "\n",
        "plt.hist(food_choices_cleaned_df['breakfast'], alpha = .5)\n",
        "plt.hist(food_choices_cleaned_df['fries'], alpha = .5)\n",
        "\n",
        "'''There is an extensive preference for the first option in both of these\n",
        "responses and they are unlikely to yield any deeper insight. Given that three\n",
        "other operable food identification questions exist, testing can proceed with \n",
        "only the remaining variables; the breakfast and fries columns will be omitted \n",
        "from the analysis.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As7BHUExmmUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Is there a correlation between respondents' self-identification with\n",
        "healthier/unhealthier food options and academic performance? Given that \n",
        "self-identification food responses are between two coded options, and the \n",
        "goal is to compare more than two unmatched groups, a Chi-Square test is \n",
        "appropriate.'''\n",
        "\n",
        "# execute a Chi-square test for all values\n",
        "id_contingency = pd.crosstab(index=food_choices_cleaned_df['GPA'], \n",
        "                          columns=[food_choices_cleaned_df['coffee'], \n",
        "                                   food_choices_cleaned_df['drink'], \n",
        "                                   food_choices_cleaned_df['soup']])\n",
        "\n",
        "stat, p, dof, expected = stats.chi2_contingency(id_contingency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6i663cHfO2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''The p-value would be a relevant measure of significance. Usually set\n",
        "at 0.05, the sample size merits reevaluation of this standard. Using the \n",
        "below table, provided by the author's mentor, a closer approximation of \n",
        "significance can be determined.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXlPpNSrdsIM",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://github.com/AmpleOpportunity/nutrition-vs-academics/blob/master/P-value%20based%20off%20sample%20size.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss29cTFfdAP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate an appropriate p-value for holding a strong standard for evidence\n",
        "x = np.array([.005, .003, .001, .0003])\n",
        "y = np.array([30, 50, 100, 1000])\n",
        "a = np.vstack([x, np.ones(len(x))]).T\n",
        "\n",
        "'''Given that we only have four data points that span a large sample size range\n",
        "with fleetingly small p-value thresholds, there is no \"silver bullet\" \n",
        "function (linear, quadratic, logarithmic) that's going to fit these points\n",
        "perfectly. For this reason, a least-squares approach has been selected to \n",
        "fit with the intention of minimizing residuals.'''\n",
        "\n",
        "# use least-squares to model regression line\n",
        "m, c = np.linalg.lstsq(a, y, rcond=None)[0]\n",
        "\n",
        "# using the slope-intercept form of a line, find the p-value at the sample size\n",
        "pval = (len(food_choices_cleaned_df) - c) / m\n",
        "\n",
        "# plot the least-squares result\n",
        "plt.plot(x, y, 'o', label='Original data', markersize = 10)\n",
        "plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('Given a sample size of {}, the p-value should be approximated as {} using the least-squared method.'.format(\n",
        "    len(food_choices_cleaned_df), round(pval, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYj3X9V9fRRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# interpret the test statistic\n",
        "prob = 1 - pval\n",
        "critical = stats.chi2.ppf(prob, dof)\n",
        "print('Stat: ' + str(abs(stat)),' Critical: ' + str(critical), 'P: ' + str(p))\n",
        "\n",
        "'''We fail to reject the null hypothesis that there is no correlation between \n",
        "respondents' self-identification with healthier/unhealthier food options and \n",
        "academic performance.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P-KFC8S5nug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create boxplot to represent data\n",
        "\n",
        "# convert coded responses into readable values\n",
        "replacements_for_one = [{'coffee': 1, 'drink': 1, 'soup': 1,}, \n",
        "                        {'coffee': 'Frappuccino', 'drink': 'Soda', 'soup': 'Creamy'}]\n",
        "replacements_for_two = [{'coffee': 2, 'drink': 2, 'soup': 2}, \n",
        "                        {'coffee': 'Espresso', 'drink': 'Orange Juice', 'soup': 'Vegetable'}]\n",
        "\n",
        "boxplot_df = food_choices_cleaned_df\n",
        "boxplot_df = boxplot_df.replace(replacements_for_one[0], replacements_for_one[1])\n",
        "boxplot_df = boxplot_df.replace(replacements_for_two[0], replacements_for_two[1])\n",
        "\n",
        "# generate boxplots\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14,4))\n",
        "f.suptitle('GPA vs. Identification with Food Items', fontsize=14)\n",
        "bplot = sns.boxplot(x='coffee', y='GPA', data=boxplot_df, ax=ax1)\n",
        "bplot = sns.boxplot(x='drink', y='GPA', data=boxplot_df, ax=ax2)\n",
        "bplot = sns.boxplot(x='soup', y='GPA', data=boxplot_df, ax=ax3)\n",
        "\n",
        "# write to file for use in presentation\n",
        "fig = bplot.get_figure()\n",
        "fig.savefig('id_axis_boxplot.png', dpi=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyNR87tHxOZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Is there a correlation between respondents' successful identification of the\n",
        "caloric content in food items versus their academic performance? Responses are\n",
        "also structured categorically and across multiple samples so a Chi-Square will\n",
        "again be used for this analysis.'''\n",
        "\n",
        "cal_contingency = pd.crosstab(index = food_choices_cleaned_df['GPA'], \n",
        "                           columns=[food_choices_cleaned_df['calories_chicken'], \n",
        "                                    food_choices_cleaned_df['calories_scone'], \n",
        "                                    food_choices_cleaned_df['tortilla_calories'], \n",
        "                                    food_choices_cleaned_df['waffle_calories']])\n",
        "\n",
        "cal_stat, cal_p, cal_dof, cal_expected = stats.chi2_contingency(cal_contingency)\n",
        "\n",
        "cal_critical = stats.chi2.ppf(prob, cal_dof)\n",
        "print('Stat: ' + str(abs(cal_stat)),' Critical: ' + str(cal_critical), 'P: ' + str(cal_p))\n",
        "\n",
        "'''These results are of great interest. If the standard 0.05 p-value assumption \n",
        "were adopted, then an argument could be made that the results are statistically\n",
        "significant. Given our computed p-value of 0.0035, we must instead fail to \n",
        "reject the null hypothesis. This marginal deviation is further validated by our \n",
        "chi-squared value vs. our critical value with 1853.422 only being about 3% shy \n",
        "of significance at a critical value of 1912.696.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaD-b_TjAMWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a boxplot to represent data\n",
        "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(19,4))\n",
        "f.suptitle('GPA vs. Caloric Estimation', fontsize=14)\n",
        "bplot0 = sns.boxplot(x='calories_chicken', y='GPA', data=boxplot_df, ax=ax1)\n",
        "bplot1 = sns.boxplot(x='calories_scone', y='GPA', data=boxplot_df, ax=ax2)\n",
        "bplot2 = sns.boxplot(x='tortilla_calories', y='GPA', data=boxplot_df, ax=ax3)\n",
        "bplot3 = sns.boxplot(x='waffle_calories', y='GPA', data=boxplot_df, ax=ax4)\n",
        "\n",
        "# iterate through plots and assign them all a default color\n",
        "plotlist = [bplot0, bplot1, bplot2, bplot3]\n",
        "for plot in plotlist:\n",
        "  for box in plot.artists:\n",
        "    box.set_facecolor(sns.xkcd_rgb['windows blue'])\n",
        "\n",
        "# highlight correct answers\n",
        "bplot0.artists[3].set_facecolor(sns.xkcd_rgb['faded green'])\n",
        "bplot1.artists[1].set_facecolor(sns.xkcd_rgb['faded green'])\n",
        "bplot2.artists[2].set_facecolor(sns.xkcd_rgb['faded green'])\n",
        "bplot3.artists[1].set_facecolor(sns.xkcd_rgb['faded green'])\n",
        "\n",
        "# write to file for use in presentation\n",
        "f.savefig('calorie_estimation_boxplot.png', dpi=400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WItqP0G2HJjR",
        "colab_type": "text"
      },
      "source": [
        "## Further Study\n",
        "The major question of this investigation has been satisfied; we fail to reject the null hypothesis that students who are more likely to identify with healthier meal options and more accurately predict the caloric density of foods, on average, have higher academic performance as measured by GPA.\n",
        "\n",
        "The results of the last experiment yielded insights that, while not statistically significant within the parameters defined, exhibited a weak correlation that merits additional investigation.\n",
        "\n",
        "The intention of this writing has focused on the subjects' self-evaluation of food items but would also benefit from analyzing subjects' self-identification of *themselves* with regard to nutrition habits. The study has been appended to investigate a second question: Is there a correlation between respondents' self-perception of their own dietary identification and nutritional habits vs academic performance exists.\n",
        "\n",
        "This additional hypothesis will be tested by evaluating subjects' current \n",
        "assessment of their diet (healthy\\balanced\\moderated, unhealthy\\cheap\\too much\\random, the same thing over and over, unclear), perception of their body weight (slim, very fit, just right, slightly overweight, overweight, does not regard body in terms of weight), and frequency that nutritional values are checked for food items (never, on certain products only, very rarely, on most products, on everything)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_QayinsFOa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataframe with isolated responses\n",
        "self_assessment_df = food_choices_master_df[['GPA', 'diet_current_coded', \n",
        "                                             'self_perception_weight', \n",
        "                                             'nutritional_check']]                                        \n",
        "\n",
        "# drop records where missing/non-numerical values exist\n",
        "self_assessment_df['GPA'] = pd.to_numeric(self_assessment_df['GPA'], \n",
        "                                               errors='coerce')\n",
        "\n",
        "self_assessment_df = self_assessment_df.dropna()\n",
        "\n",
        "\n",
        "self_assessment_df.info()\n",
        "self_assessment_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2m7AGexO8sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate a new p-value from the new sample size using the least-squares\n",
        "# results from before\n",
        "pval_for_self_assessment = pval = (len(self_assessment_df) - c) / m\n",
        "\n",
        "print(pval_for_self_assessment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqa5ffcHP9PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assess correlation between GPA and self-identification using a Pearson Correlation\n",
        "print(stats.pearsonr(self_assessment_df['GPA'], self_assessment_df['diet_current_coded']))\n",
        "print(stats.pearsonr(self_assessment_df['GPA'], self_assessment_df['self_perception_weight']))\n",
        "print(stats.pearsonr(self_assessment_df['GPA'], self_assessment_df['nutritional_check']))\n",
        "\n",
        "'''We fail to reject the null hypothesis based upon the association of these\n",
        "values independently. A comparison of all values against GPA is also of interest.'''\n",
        "\n",
        "# assess correlation between GPA and self-identification using Chi-squared Test\n",
        "self_assessment_contingency = pd.crosstab(index = self_assessment_df['GPA'], \n",
        "                           columns=[self_assessment_df['diet_current_coded'], \n",
        "                                    self_assessment_df['self_perception_weight'], \n",
        "                                    self_assessment_df['nutritional_check']])\n",
        "\n",
        "sa_stat, sa_p, sa_dof, sa_expected = stats.chi2_contingency(self_assessment_contingency)\n",
        "\n",
        "sa_critical = stats.chi2.ppf(prob, sa_dof)\n",
        "print('Stat: ' + str(abs(sa_stat)),' Critical: ' + str(sa_critical), 'P: ' + str(sa_p))\n",
        "\n",
        "'''We once again fail to reject the null.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpJg-aDnRPGl",
        "colab_type": "text"
      },
      "source": [
        "## Findings\n",
        "While poor dietary habits often preexist health complications, its effect on academic performance, as measured by GPA, cannot be said to exist in this examination. No correlation between subjects' self-identification with food items, correct identification of caloric content of food items, or self-assessment of body and nutritional habits vs GPA was found to exist.\n",
        "\n",
        "While there is sometimes a reluctance to publish a null hypothesis, there is often value in understanding what something isn't. This study may still be useful to educators and providers of academic services if only as a reference by which to eliminate non-value added areas to concentrate their efforts.\n",
        "\n",
        "## Limitations\n",
        "1. The computed p-value was of great trouble, in both selecting a method of calculation and comparing that against the caloric identification results. The least-squares results were computed liniarly where the actual data clearly illustrates a polynomial relationship between the points. This area would benefit from further exploration with additional data sets.\n",
        "1. Even without rejecting the null hypothesis, caloric identification must be scrutinized by the maxim, \"correlation does not imply causation.\" Healthy dietary habits may be a function of information, of which a higher-performing subjects might have a more robust understanding of.\n",
        "1. In the final assessment, the data values are coded by the survey author whose sorting methodologies are not clearly stated. This breakdown introduces opportunities for bias among the coded samples as they likely come as a product of the author's interpretation of responses."
      ]
    }
  ]
}