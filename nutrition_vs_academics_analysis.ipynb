{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nutrition-vs-academics-analysis",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQn7a2HETZ11p61RCcUTN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmpleOpportunity/nutrition-vs-academics/blob/master/nutrition_vs_academics_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVrC1emKklc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Students who are more likely to identify with healthier meal options and more \n",
        "accurately predict the caloric density of foods, on average, have higher \n",
        "academic performance as measured by GPA.'''\n",
        "\n",
        "# dependencies\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statsmodels.sandbox.stats.runs as sm\n",
        "\n",
        "\n",
        "# read csv to dataframe\n",
        "host = 'https://raw.githubusercontent.com/AmpleOpportunity/nutrition-vs-academics/master/food_coded.csv'\n",
        "food_choices_master_df = pd.read_csv(host)\n",
        "food_choices_master_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vxTu4rXr6EU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''For the purposes of this study, the only fields that will be used are those\n",
        "that contain food self-identification choices (calories_chicken, coffee, drink, \n",
        "fries, soup) as well as caloric identification of various food items \n",
        "(calories_chicken, calories_scone, tortilla_calories, waffle_calories) with GPA \n",
        "as the continuous variable throughout.'''\n",
        "\n",
        "# extract relevant data points for cleaning\n",
        "food_choices_extracted_df = food_choices_master_df[['GPA', 'breakfast', 'coffee', \n",
        "                                                   'drink', 'fries', 'soup', 'calories_chicken', \n",
        "                                                   'calories_scone', \n",
        "                                                   'tortilla_calories', \n",
        "                                                   'waffle_calories']]\n",
        "\n",
        "food_choices_extracted_df.info()\n",
        "\n",
        "'''The schema reveals some needed work before analysis. A few of the records are \n",
        "incomplete. Additionally, all data types should be interpreted as an integer or \n",
        "floating point number but GPA is interpreted as a string. All non-numerical \n",
        "records will be converted into null values for that column and then purged from \n",
        "the dataframe.'''\n",
        "\n",
        "# drop records where missing/non-numerical values exist\n",
        "food_choices_extracted_df['GPA'] = pd.to_numeric(food_choices_extracted_df['GPA'], \n",
        "                                               errors='coerce')\n",
        "\n",
        "food_choices_cleaned_df = food_choices_extracted_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkhuDUxHGow2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verify new sample size integrity\n",
        "print('{} records removed. Total records: {}.'.format(\n",
        "    len(food_choices_extracted_df) - len(food_choices_cleaned_df), \n",
        "    len(food_choices_cleaned_df)))\n",
        "\n",
        "'''The sample size is still robust enough to continue analysis.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FUC6evFbAoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comparing each group for normality by extracting kurtosis and skewness\n",
        "\n",
        "# create separate df to hold values\n",
        "normality_analysis_df = pd.DataFrame(columns=['name', 'kurtosis', 'skewness'])\n",
        "\n",
        "# iterate over food_choices_cleaned_df, compute kurtosis/skew, and append\n",
        "# results to normality_analysis_df\n",
        "for i in range(len(food_choices_cleaned_df.columns)):\n",
        "  normality_analysis_df = normality_analysis_df.append(pd.Series([food_choices_cleaned_df.columns[i],\n",
        "                                          stats.kurtosis(food_choices_cleaned_df.iloc[:, i]),\n",
        "                                          stats.skew(food_choices_cleaned_df.iloc[:, i])],\n",
        "                                         index=normality_analysis_df.columns),\n",
        "                               ignore_index=True)\n",
        "\n",
        "normality_analysis_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR7F2RaR-i5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''All skews are within acceptable ranges. breakfast and fries are leptokurtic.\n",
        "Further investigation is warranted.'''\n",
        "\n",
        "plt.hist(food_choices_cleaned_df['breakfast'], alpha = .5)\n",
        "plt.hist(food_choices_cleaned_df['fries'], alpha = .5)\n",
        "\n",
        "'''There is an extensive preference for the first option in both of these\n",
        "responses and they are unlikely to yield any deeper insight. Given that three\n",
        "other operable food identification questions exist, testing can proceed with \n",
        "only the remaining variables; the breakfast and fries columns will be omitted \n",
        "from the analysis.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As7BHUExmmUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Is there a correlation between respondents' self-identification with\n",
        "healthier/unhealthier food options and academic performance? Given that \n",
        "self-identification food responses are between two coded options, and the \n",
        "goal is to compare more than two unmatched groups, a Chi-Square test is \n",
        "appropriate.'''\n",
        "\n",
        "# execute a Chi-square test for all values\n",
        "id_contingency = pd.crosstab(index=food_choices_cleaned_df['GPA'], \n",
        "                          columns=[food_choices_cleaned_df['coffee'], \n",
        "                                   food_choices_cleaned_df['drink'], \n",
        "                                   food_choices_cleaned_df['soup']])\n",
        "\n",
        "stat, p, dof, expected = stats.chi2_contingency(id_contingency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6i663cHfO2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''The p-value would be a relevant measure of significance. Usually set\n",
        "at 0.05, the sample size merits reevaluation of this standard. Using the \n",
        "below table, a closer approximation of significance can be determined.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXlPpNSrdsIM",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://github.com/AmpleOpportunity/nutrition-vs-academics/blob/master/P-value%20based%20off%20sample%20size.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss29cTFfdAP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate an appropriate p-value for holding a strong standard for evidence\n",
        "x = np.array([.005, .003, .001, .0003])\n",
        "y = np.array([30, 50, 100, 1000])\n",
        "a = np.vstack([x, np.ones(len(x))]).T\n",
        "\n",
        "'''Given that we only have four data points that span a large sample size range\n",
        "with fleetingly small p-value thresholds, there is no \"silver bullet\" \n",
        "function (linear, quadratic, logarithmic) that's going to fit these points\n",
        "perfectly. For this reason, a least-squares approach has been selected to \n",
        "fit with the intention of minimizing residuals.'''\n",
        "\n",
        "# use least-squares to model regression line\n",
        "m, c = np.linalg.lstsq(a, y, rcond=None)[0]\n",
        "\n",
        "# using the slope-intercept form of a line, find the p-value at the sample size\n",
        "pval = (len(food_choices_cleaned_df) - c) / m\n",
        "\n",
        "# plot the least-squares result\n",
        "plt.plot(x, y, 'o', label='Original data', markersize = 10)\n",
        "plt.plot(x, m*x + c, 'r', label='Fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('Given a sample size of {}, the p-value should be approximated as {} using the least-squared method.'.format(\n",
        "    len(food_choices_cleaned_df), round(pval, 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYj3X9V9fRRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# interpret the test statistic\n",
        "prob = 1 - pval\n",
        "critical = stats.chi2.ppf(prob, dof)\n",
        "print('Stat: ' + str(abs(stat)),' Critical: ' + str(critical), 'P: ' + str(p))\n",
        "\n",
        "'''We fail to reject the null hypothesis that there is no correlation between \n",
        "respondents' self-identification with healthier/unhealthier food options and \n",
        "academic performance.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyNR87tHxOZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Is there a correlation between respondents' successful identification of the\n",
        "caloric content in food items versus their academic performance? Responses are\n",
        "also structured categorically and across multiple samples so a Chi-Square will\n",
        "again be used for this analysis.'''\n",
        "\n",
        "cal_contingency = pd.crosstab(index = food_choices_cleaned_df['GPA'], \n",
        "                           columns=[food_choices_cleaned_df['calories_chicken'], \n",
        "                                    food_choices_cleaned_df['calories_scone'], \n",
        "                                    food_choices_cleaned_df['tortilla_calories'], \n",
        "                                    food_choices_cleaned_df['waffle_calories']])\n",
        "\n",
        "cal_stat, cal_p, cal_dof, cal_expected = stats.chi2_contingency(cal_contingency)\n",
        "\n",
        "cal_critical = stats.chi2.ppf(prob, cal_dof)\n",
        "print('Stat: ' + str(abs(cal_stat)),' Critical: ' + str(cal_critical), 'P: ' + str(cal_p))\n",
        "\n",
        "'''These results are of great interest. If the standard 0.05 p-value assumption \n",
        "were adopted, then an argument could be made that the results are statistically\n",
        "significant. Given our computed p-value of 0.0035, we must instead fail to \n",
        "reject the null hypothesis. This marginal deviation is further validated by our \n",
        "chi-squared value vs. our critical value with 1853.422 only being about 3% shy \n",
        "of significance at a critical value of 1912.696.'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}